---
title: "Image_Classification"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Image Classification

This Data contains around 25k images of size 150x150 distributed under 6 categories.
{'buildings' -> 0,
'forest' -> 1,
'glacier' -> 2,
'mountain' -> 3,
'sea' -> 4,
'street' -> 5 }

The Training data is in shape of (Number of Training Images, Width of image, Height of image, Channel of image). This shape is very important. If you didnot resize the images to same size. It should be (No. of images,) shape. So, using this shape you cant feed the images to the model.

## Neural Network

#### One time run to install package EBImage
```{r}
#install.packages("BiocManager") 
#BiocManager::install("EBImage")
```

#### Import all required packages
```{r}
library(EBImage)
```

#### Install Keras and Tensorflow - One time run only
```{r}
library(keras)
library(tensorflow)
```


#### Build a function to map each image with corresponding numeric vector and with its respective labels
```{r}
get_images <- function(directory){
  Images <- list()
  Labels <- list() 
  Labels_final <- list()
  # 0 for Building , 1 for forest, 2 for glacier, 3 for mountain, 4 for Sea , 5 for Street
  label <- 0 
  i <- 1
  Images_final <- NULL
  for (labelss in list.files(directory)){
    print(labelss)
    if(labelss == 'glacier'){ #Folder contain Glacier Images get the '2' class label.
      label = 2 
      }else if(labelss == 'sea'){
        label = 4
      }else if(labelss == 'buildings'){
        label = 0
      }else if(labelss == 'forest'){
        label = 1
      }else if(labelss == 'street'){
        label = 5
      }else if(labelss == 'mountain'){
        label = 3
      }
    print(label)
    for(image_file in list.files(paste0(directory,"/",labelss))){               #Extracting the file name of the image from Class Label folder
      Images[[image_file]] <- readImage(paste0(directory,"/",labelss,"/",image_file))
      Images[[image_file]] <- resize(Images[[image_file]], 128,128)
      Images[[image_file]] <- array_reshape(Images[[image_file]], c(128,128,3))
      Images_final <- rbind(Images_final, Images[[image_file]])
      Labels[i] <- label
      Labels_final[[image_file]] <- label
      i <- i+1
    }
  }
  final_list <- list(Images,Labels,Images_final,Labels_final)
  return (final_list)
}

```

#### Prepare train data 
```{r}
final_list <- get_images("C:/Users/datamining/Downloads/intel-image-classification/seg_train/seg_train")
final_list_train<- final_list[[1]]

trainx <- final_list[[3]]

labelstrain <- unlist(final_list[[2]])
```


```{r}
install_tensorflow()
```


#### One hot encoding
```{r}
trainlabels <- to_categorical(final_list[[2]])
View(trainlabels)
```
####  Build Model in Keras-Tensorflow
##   we initiated our sequential feedforward DNN architecture with keras_model_sequential() and then add some dense layers
##  the first with 256 nodes and the second with 128, followed by an output layer with 6 nodes.
##  first layer needs the input_shape argument to equal the number of features in the data; however, the successive layers are able to dynamically interpret the number of expected         inputs based on the previous layer.
#  When using rectangular data, the most common approach is to use ReLU activation functions in the hidden layers. The ReLU activation function is simply taking the summed weighted        inputs and transforming them to a  0(not fire) or > 0(fire) if there is enough signal


```{r}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 256, activation = 'relu', input_shape = c(49152)) %>%
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dense(units = 6, activation = 'softmax')
summary(model)
```

#### Compile
## To incorporate the backpropagation piece of our DNN we include compile()

```{r}
model %>%
  compile(loss = 'sparse_categorical_crossentropy',
          optimizer = optimizer_rmsprop(),
          metrics = c('accuracy'))

```

#### Fit Model
```{r}
history <- model %>%
  fit(trainx,
      labelstrain,
      epochs = 35,
      batch_size = 32,
      validation_split = 0.3)
```


```{r}
plot(history)
```


#### Evaluation & Prediction - train data
```{r}
model %>% evaluate(trainx,labelstrain)
pred <- model %>% predict_classes(trainx)
table(Predicted = pred, Actual = labelstrain)
prob <- model %>% predict_proba(trainx)
cbind(prob, Prected = pred, Actual= labelstrain)
```

#### Test the model 
```{r}
final_list_test <- get_images("C:/Users/datamining/Downloads/intel-image-classification/seg_test/seg_test") # Give the appropriate path

testx <- final_list_test[[3]]

labelstest <- unlist(final_list_test[[2]])
```


#### Evaluation & Prediction - test data
```{r}
model %>% evaluate(testx,labelstest)
pred <- model %>% predict_classes(testx)
table(Predicted = pred, Actual = labelstest,dnn=c("Actual","Prediction"))
prob <- model %>% predict_proba(testx)
cbind(prob, Prected = pred, Actual= labelstest)

outputnn <- data.frame(Actual = labelstest,Predicted = pred )
outputnn
```


## Support Vector Machine Algorithm

```{r}
library(e1071)
library(pROC)
library(caret)
```

#### Build a function to map each image with corresponding numeric vector and with its respective labels
```{r}
get_images <- function(directory){
  Images <- list()
  Labels <- list() # 0 for Building , 1 for forest, 2 for glacier, 3 for mountain, 4 for Sea , 5 for Street
  label <- 0
  i <- 0
  for (labelss in list.files(directory)){
    print(labelss)
    if(labelss == 'glacier'){ #Folder contain Glacier Images get the '2' class label.
      label = 2
    }else if(labelss == 'sea'){
      label = 4
    }else if(labelss == 'buildings'){
      label = 0
    }else if(labelss == 'forest'){
      label = 1
    }else if(labelss == 'street'){
      label = 5
    }else if(labelss == 'mountain'){
      label = 3
    }
    print(label)
    for(image_file in list.files(paste0(directory,"/",labelss))){ #Extracting the file name of the image from Class Label folder
      Images[[image_file]] <- readImage(paste0(directory,"/",labelss,"/",image_file))
      Images[[image_file]] <- resize(Images[[image_file]], 30,30)
      Images[[image_file]] <- array_reshape(Images[[image_file]], c(30,30,3))
      Labels[[image_file]] <- label
      i <- i+1
    }
  }
  final_list <- list(Images,Labels)
  return (final_list)
}

```

#### Training data importing with labelling 
```{r}
final_list <- get_images("C:/Users/datamining/Downloads/intel-image-classification/seg_train/seg_train")

#Predictor variables

final_list_train<- final_list[[1]]

# Data preparation 

df <- data.frame(matrix(unlist(final_list_train), nrow=length(final_list_train), byrow=T))

df_z <- data.frame(matrix(unlist(final_list[[2]]), nrow=length(final_list[[2]]), byrow=T))

colnames(df_z) <- "label"

svm_inp <- cbind(df,df_z)

svm_inp$label <- as.factor(svm_inp$label)
```


```{r}
# Test data importing with labelling 

final_list_test <- get_images("C:/Users/datamining/Downloads/intel-image-classification/seg_test/seg_test")

#Predictor variables

final_list_test_x<- final_list_test[[1]]

# Data preparation 

df_test <- data.frame(matrix(unlist(final_list_test_x), nrow=length(final_list_test_x), byrow=T))

df_label_test <- data.frame(matrix(unlist(final_list_test[[2]]), nrow=length(final_list_test[[2]]), byrow=T))

colnames(df_label_test) <- "label"

test_set <- cbind(df_test,df_label_test)

test_set$label <- as.factor(test_set$label)



# Fitting SVM

svm_fit <- train(label ~., svm_inp, method = "svmLinear",
                 preProcess = c("center", "scale"),
                 tuneLength = 10)


## predict svm
test_pred_svm <- predict(svm_fit, newdata = test_set)

svm_result <- confusionMatrix(test_pred_svm,test_set$label,dnn=c("Actual","Prediction"))
print(svm_result)


outputsvm <- data.frame(Actual = test_set$label,Predicted = test_pred_svm )
outputsvm
```


```{r}
# roc svm, AUC
roc_inp_SVM <- multiclass.roc(test_set$label, as.numeric(test_pred_svm))

print(auc(roc_inp_SVM))

rs <- roc_inp_SVM[['rocs']]

plot(rs[[2]], type = "l", col = "blue", xlab = "False Positive Rate", ylab = "True Positive Rate", main = "SVM - ROC")
axis(1, seq(0.0,1.0,0.1))
axis(2, seq(0.0,1.0,0.1))
abline(h=seq(0.0,1.0,0.1), v=seq(0.0,1.0,0.1), col="gray", lty=3)
```

## Naive Bayes

```{r}
# Fitting NB 
nb_fit <- train(label ~., svm_inp, method = "naive_bayes",
                preProcess = c("center", "scale"),
                tuneLength = 10)


test_pred_nb <- predict(nb_fit, newdata = test_set)

nb_result <- confusionMatrix(test_pred_nb,test_set$label)
print(nb_result)

outputnb <- data.frame(Actual = test_set$label,Predicted = test_pred_nb )
outputnb

```


```{r}
# NB ROC and AUC
roc_inp_nb <- multiclass.roc(test_set$label, as.numeric(test_pred_nb))
```


```{r}
print(auc(roc_inp_nb))
```

```{r}
rs_nb <- roc_inp_nb[['rocs']]

plot(rs_nb[[1]], type = "l", col = "blue", xlab = "False Positive Rate", ylab = "True Positive Rate", main = "NB - ROC")
axis(1, seq(0.0,1.0,0.1))
axis(2, seq(0.0,1.0,0.1))
abline(h=seq(0.0,1.0,0.1), v=seq(0.0,1.0,0.1), col="gray", lty=3)
```

## Random Forest

```{r}
# Fitting Random forest

control <- trainControl(method='repeatedcv', 
                        number=6, 
                        repeats=1)

test_set_p1 = svm_inp[c(1,2:1500,2701)]

rf_default <- train(label~., 
                    data=test_set_p1, 
                    method='rf', 
                    metric='Accuracy', 
                    trControl=control)

test_pred_rf <- predict(rf_default, newdata = test_set)

rf_result <- confusionMatrix(test_pred_rf,test_set$label,dnn=c("Actual","Prediction"))

print(rf_result)


outputrf <- data.frame(Actual = test_set$label,Predicted = test_pred_rf )
outputrf
```


```{r}
# RF AUC,ROC

roc_inp_rf <- multiclass.roc(test_set$label, as.numeric(test_pred_rf))

print(auc(roc_inp_rf))

rs_rf <- roc_inp_rf[['rocs']]


plot(rs_rf[[1]], type = "l", col = "blue", xlab = "False Positive Rate", ylab = "True Positive Rate", main = "RF - ROC")
axis(1, seq(0.0,1.0,0.1))
axis(2, seq(0.0,1.0,0.1))
abline(h=seq(0.0,1.0,0.1), v=seq(0.0,1.0,0.1), col="gray", lty=3)


```

# Hypothesis testing :ANOVA 

```{r}
outputrf$accuracy <- ifelse(outputrf$Actual == outputrf$Predicted,1,0)
outputnb$accuracy <- ifelse(outputnb$Actual == outputnb$Predicted,1,0)
outputnn$accuracy <- ifelse(outputnn$Actual == outputnn$Predicted,1,0)
outputsvm$accuracy<- ifelse(outputsvm$Actual==outputsvm$Predicted,1,0)

# Identifying the significance difference

outputrf$results <- as.factor("RandomForest")
outputnb$results <- as.factor("Naive Bayes") 
outputnn$results <- as.factor("Deep Learning")
outputsvm$results <- as.factor("SupportVector")

#rbind
outcome <- rbind(outputrf,outputnb,outputsvm,outputnn)

#anova
aovfit <- aov(data = outcome, formula = accuracy ~ results)
summary(aovfit)
```

#Plotting the graph for the accuracy comparision 
```{r}
p <- ggplot( data = outcome, mapping = aes(x = results, y =accuracy/10 ,fill = results))+ 
  geom_bar(stat = "identity") +
  labs(x = "Models" , y = "Accuracy")
p <- p + guides(fill=guide_legend(title="Models"))
p
```
